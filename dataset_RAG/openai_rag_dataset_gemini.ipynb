{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ace_tools in c:\\users\\hayde\\onedrive - logical aspect\\education\\unisa\\inft3039 - capstone 1\\.venv\\lib\\site-packages (0.0)\n"
     ]
    }
   ],
   "source": [
    "# %pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "\n",
    "\n",
    "# !pip install -qU \"langchain[openai]\"\n",
    "# !pip install -qU langchain-pinecone\n",
    "# !pip install -qU langchain-mongodb\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install pyarrow fastparquet\n",
    "# !pip install ace_tools\n",
    "# !pip install langsmith\n",
    "# %pip install --upgrade --quiet  google-ai-generativelanguage==0.6.1\n",
    "# %pip install --upgrade --quiet  langchain-google-genai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# import ace_tools as tools\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "import langsmith\n",
    "import getpass\n",
    "import os\n",
    "import json\n",
    "from pydantic.v1 import BaseModel\n",
    "from langchain.chat_models import init_chat_model\n",
    "import getpass\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n",
    "\n",
    "# llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "\n",
    "# embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prompt', 'essay', 'evaluation', 'band', 'cleaned_evaluation',\n",
       "       'Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar',\n",
       "       'Overall Band Score', 'word_count', 'sentence_count',\n",
       "       'avg_sentence_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  load csv to dataframe\n",
    "# df = pd.read_csv(r\"C:\\Users\\hayde\\University of South Australia\\USO_Capstone Projects 2025 (SP1 SP3) - Group A - Group A\\Assessment 1\\Training Data\\processed_dataset2_train_data_top100.csv\")\n",
    "# df.head()\n",
    "\n",
    "# Define the GitHub raw CSV URL\n",
    "csv_url = \"https://github.com/haydenkerr/INFT3039-Capstone1-GroupA-25/raw/refs/heads/main/datasets/processed_dataset2_train_data.csv\"\n",
    "# Load the CSV data\n",
    "df = pd.read_csv(csv_url)\n",
    "\n",
    "\n",
    "\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'prompt', 'essay', 'evaluation', 'band', 'cleaned_evaluation','Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar','Overall Band Score', 'word_count', 'sentence_count','avg_sentence_length'\n",
    "df = df[['prompt', 'essay', 'band', 'cleaned_evaluation','Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar','Overall Band Score']]  \n",
    "\n",
    "df.rename(columns={'prompt':'question'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert each row to a Document object from the dataframe\n",
    "# if rows > 10 , then break for testing\n",
    "docs = []\n",
    "max_rows = 5000\n",
    "processed_rows = 0\n",
    "for _, row in df.iterrows():\n",
    "    if processed_rows >= max_rows:\n",
    "        break\n",
    "    docs.append(\n",
    "        Document(\n",
    "            page_content=f\"question: {row['question']}\\nessay: {row['essay']}\\nband: {row['band']} \\ncleaned_evaluation: {row['cleaned_evaluation']}\\nTask Achievement: {row['Task Achievement']}\\nCoherence: {row['Coherence']}\\nLexical Resource: {row['Lexical Resource']}\\nGrammar: {row['Grammar']}\\nOverall Band Score: {row['Overall Band Score']}\"\n",
    "        )\n",
    "    )\n",
    "    processed_rows += 1\n",
    "\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "# Initialize In-Memory Vector Store\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_documents(all_splits)\n",
    "\n",
    "# Load LLM and prompt\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Define State for LLM workflow\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    essay: str\n",
    "    context: List[Document]\n",
    "    graded_response: str\n",
    "\n",
    "# Retrieval function\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "# Grading function\n",
    "def grade(state: State):\n",
    "    example_texts = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    user_input = f\"New question: {state['question']}\\nNew Essay: {state['essay']}\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \n",
    "            \"\"\"You are an IELTS examiner. Score the given essay based on the 0-9 IELTS band scale. \n",
    "            The output should be a json object with the following keys:\n",
    "            'question','essay','overall score', 'overall feedback','task achievement score', 'task achievement feedback',\n",
    "            'coherence score', 'coherence feedback', 'lexical resource score', 'lexical resource feedback',\n",
    "            'grammar score', 'grammar feedback'.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here are some example graded essays:\\n{example_texts}\\n\\nNow, evaluate this new essay:\\n{user_input}\"}\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    return {\"graded_response\": response.content}\n",
    "\n",
    "# Build Graph\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, grade])\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'essay', 'band', 'cleaned_evaluation', 'Task Achievement',\n",
       "       'Coherence', 'Lexical Resource', 'Grammar', 'Overall Band Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test data set\n",
    "# Define the GitHub raw CSV URL\n",
    "\n",
    "\n",
    "# Define the GitHub raw CSV URL\n",
    "csv_url_test = \"https://github.com/haydenkerr/INFT3039-Capstone1-GroupA-25/raw/refs/heads/main/datasets/processed_dataset2_test_data.csv\"\n",
    "# Load the CSV data\n",
    "df_test = pd.read_csv(csv_url_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_test = df_test[['prompt', 'essay', 'band', 'cleaned_evaluation','Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar','Overall Band Score']]  \n",
    "\n",
    "df_test.rename(columns={'prompt':'question'}, inplace=True)\n",
    "\n",
    "df_test.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>essay</th>\n",
       "      <th>band</th>\n",
       "      <th>cleaned_evaluation</th>\n",
       "      <th>Task Achievement</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Lexical Resource</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Overall Band Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interv...</td>\n",
       "      <td>To agr...</td>\n",
       "      <td>6.5\\n\\...</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The in...</td>\n",
       "      <td>It is ...</td>\n",
       "      <td>8\\n\\n\\...</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The in...</td>\n",
       "      <td>It is ...</td>\n",
       "      <td>8.5\\n\\...</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The in...</td>\n",
       "      <td>The pr...</td>\n",
       "      <td>&lt;4\\n\\n...</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The in...</td>\n",
       "      <td>In rec...</td>\n",
       "      <td>4\\n\\n\\...</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question      essay       band cleaned_evaluation  Task Achievement  \\\n",
       "0  Interv...  To agr...  6.5\\n\\...  Task A...                6.5          \n",
       "1  The in...  It is ...  8\\n\\n\\...  Task A...                8.5          \n",
       "2  The in...  It is ...  8.5\\n\\...  Task A...                8.5          \n",
       "3  The in...  The pr...  <4\\n\\n...  Task A...                3.0          \n",
       "4  The in...  In rec...  4\\n\\n\\...  Task A...                3.5          \n",
       "\n",
       "   Coherence  Lexical Resource  Grammar  Overall Band Score  \n",
       "0        7.0        6.5             6.5        6.5           \n",
       "1        8.0        7.5             7.0        8.0           \n",
       "2        8.0        7.5             7.0        8.5           \n",
       "3        2.0        2.5             2.0        2.5           \n",
       "4        4.0        3.5             3.5        4.0           "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Some people believe that they should be able to keep all the money they earn, and should not have to pay tax to the state. To what extent do you agree or disagree?\n",
      "Essay: It is argued by many people that all earnings should be used for their personal use rather than paying taxes to the state. I disagree with this statement as these taxes bring many advantages to society and the country.\n",
      "\n",
      "On the one hand, a huge number of individuals believe that their earned amount must be used for their own benefits, such as living expenses, utility bills, school fees, cars, and others. Also, they believe to invest in long-term or short-term plans for saving purposes as a result, they use that amount to improve their living standards. However, the masses avoid paying income tax regularly. For instance, according to a recent survey conducted by the government of Pakistan, which reveals that around 60% of the population did not pay the income tax in 2019.\n",
      "\n",
      "On the other hand, the government takes taxes for many reasons. First and foremost, medical insurance, which is free of cost for any citizen of the country in Pakistan. Also, there is a massive discount available on medicines from the insurance company. Secondly, the government spends millions of rupees to improve the infrastructure of the country, such as road construction, railways, airports, shopping malls, and others. Last but not the least, the government pays off debts from these amounts.\n",
      "\n",
      "To sum up, the government takes these tax amounts to improve its economy and fosters numerous benefits to the local community. It is a national duty of every resident to pay a small portion of their income to the government for their own advantage.\n",
      "Overall Score: 7.5\n",
      "---------\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# Example test case\n",
    "question_id = 26\n",
    "# word wrap the text output below  \n",
    "pd.set_option('display.max_colwidth',10 )\n",
    "\n",
    "\n",
    "print(\"Question: \"+df_test['question'][question_id])\n",
    "\n",
    "print(\"Essay: \"+df_test['essay'][question_id])\n",
    "print(\"Overall Score: \"+str(df_test[\"Overall Band Score\"][question_id]))\n",
    "\n",
    "\n",
    "new_question = df_test['question'][question_id]\n",
    "new_essay = df_test['essay'][question_id]\n",
    "print(\"---------\")\n",
    "\n",
    "\n",
    "# Run LLM grading\n",
    "result = graph.invoke({\"question\": new_question, \"essay\": new_essay})\n",
    "# print(result)\n",
    "print(\"---------\")\n",
    "# print(\"Predicted Band Score:\", result[\"Predicted score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 14 column 1 (char 3604)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# result_json = json.loads(result[\"graded_response\"])\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# result_json[\"overall score\"]\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# the json object returned from the grading function is stored between  ```json{ and }``` \u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# so we need to remove the first 5 characters and the last character to get the json object\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m result_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgraded_response\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m result_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverall score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\hayde\\OneDrive - Logical Aspect\\Python\\Python3.12\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\hayde\\OneDrive - Logical Aspect\\Python\\Python3.12\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\hayde\\OneDrive - Logical Aspect\\Python\\Python3.12\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 14 column 1 (char 3604)"
     ]
    }
   ],
   "source": [
    "\n",
    "# result_json = json.loads(result[\"graded_response\"])\n",
    "# result_json[\"overall score\"]\n",
    "\n",
    "# the json object returned from the grading function is stored between  ```json{ and }``` \n",
    "# so we need to remove the first 5 characters and the last character to get the json object\n",
    "result_json = json.loads(result[\"graded_response\"][8:-3])\n",
    "\n",
    "\n",
    "result_json[\"overall score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n",
      "---------\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 14 column 1 (char 3604)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# add row as list of dictionaries   \u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m result_json \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgraded_response\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m new_row \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124messay\u001b[39m\u001b[38;5;124m'\u001b[39m],\u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall Band Score\u001b[39m\u001b[38;5;124m\"\u001b[39m]),result_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverall score\u001b[39m\u001b[38;5;124m\"\u001b[39m],\u001b[38;5;28mfloat\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall Band Score\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(result_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverall score\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     18\u001b[0m rag_results\u001b[38;5;241m.\u001b[39mappend(new_row)  \n",
      "File \u001b[1;32mc:\\Users\\hayde\\OneDrive - Logical Aspect\\Python\\Python3.12\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\hayde\\OneDrive - Logical Aspect\\Python\\Python3.12\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\hayde\\OneDrive - Logical Aspect\\Python\\Python3.12\\Lib\\json\\decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m \n\u001b[0;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 14 column 1 (char 3604)"
     ]
    }
   ],
   "source": [
    "# for each row in the test data set, run the LLM grading\n",
    "# Run LLM grading for 100 rows\n",
    "rag_results = []\n",
    "processed_rows = 0\n",
    "for _, row in df_test.iterrows():\n",
    "    if processed_rows >= 100:\n",
    "        break\n",
    "    result = graph.invoke({\"question\": row['question'], \"essay\": row['essay']})\n",
    "    # add the results to the rag_results dataframe\n",
    "    # print(\"Question: \"+row['question']+ \"\\n\")\n",
    "    # print(\"Essay: \"+row['essay']+ \"\\n\")\n",
    "    # print(\"Overall Score: \"+str(row[\"Overall Band Score\"])+ \"\\n\")\n",
    "    # print(\"Predicted Band Score:\", result[\"overall score\"])\n",
    "    print(\"---------\")\n",
    "    # add row as list of dictionaries   \n",
    "    result_json = json.loads(result[\"graded_response\"][8:-3])\n",
    "    new_row = (row['question'],row['essay'],float(row[\"Overall Band Score\"]),result_json[\"overall score\"],float(row[\"Overall Band Score\"])/float(result_json[\"overall score\"]))\n",
    "    rag_results.append(new_row)  \n",
    "    processed_rows += 1\n",
    "\n",
    "# convert list of dictionaries to dataframe\n",
    "rag_results = pd.DataFrame(rag_results, columns = ['question','essay','Overall Band Score','Predicted Band Score','variation'])\n",
    "\n",
    "\n",
    "rag_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_results = pd.DataFrame(rag_results, columns = ['question','essay','Overall Band Score','Predicted Band Score','variation'])\n",
    "\n",
    "\n",
    "rag_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3268069440075547\n",
      "0.9588757307507306\n"
     ]
    }
   ],
   "source": [
    "# create accuracy score for continuos variables with sklearn\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rms = sqrt(mean_squared_error(rag_results['Overall Band Score'], rag_results['Predicted Band Score']))\n",
    "print(rms)\n",
    "print(rag_results['variation'].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

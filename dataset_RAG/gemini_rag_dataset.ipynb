{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "\n",
    "\n",
    "# !pip install -qU \"langchain[openai]\"\n",
    "# !pip install -qU langchain-pinecone\n",
    "# !pip install -qU langchain-mongodb\n",
    "# !pip install beautifulsoup4\n",
    "# !pip install pyarrow fastparquet\n",
    "# !pip install ace_tools\n",
    "# !pip install langsmith\n",
    "# %pip install --upgrade --quiet  google-ai-generativelanguage==0.6.1\n",
    "# %pip install --upgrade --quiet  langchain-google-genai \n",
    "# !pip install openpyxl\n",
    "# !pip install -qU tqdm\n",
    "# !pip install sentence-transformers    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hayde\\OneDrive - Logical Aspect\\Education\\UniSA\\INFT3039 - Capstone 1\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hayde\\OneDrive - Logical Aspect\\Education\\UniSA\\INFT3039 - Capstone 1\\.venv\\Lib\\site-packages\\keras\\src\\callbacks\\tensorboard.py:7: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\hayde\\OneDrive - Logical Aspect\\Education\\UniSA\\INFT3039 - Capstone 1\\.venv\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From c:\\Users\\hayde\\OneDrive - Logical Aspect\\Education\\UniSA\\INFT3039 - Capstone 1\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# import ace_tools as tools\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "# from .autonotebook import tqdm as notebook_tqdm\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import List, TypedDict\n",
    "import langsmith\n",
    "import getpass\n",
    "import os\n",
    "import json\n",
    "from pydantic.v1 import BaseModel\n",
    "from langchain.chat_models import init_chat_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "import getpass\n",
    "import os\n",
    "import re\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"GOOGLE_API_KEY\"):\n",
    "  os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter API key for Google Gemini: \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prompt', 'essay', 'evaluation', 'band', 'cleaned_evaluation',\n",
       "       'Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar',\n",
       "       'Overall Band Score', 'word_count', 'sentence_count',\n",
       "       'avg_sentence_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  load csv to dataframe\n",
    "# df = pd.read_csv(r\"C:\\Users\\hayde\\University of South Australia\\USO_Capstone Projects 2025 (SP1 SP3) - Group A - Group A\\Assessment 1\\Training Data\\processed_dataset2_train_data_top100.csv\")\n",
    "# df.head()\n",
    "\n",
    "# Define the GitHub raw CSV URL\n",
    "csv_url = \"https://github.com/haydenkerr/INFT3039-Capstone1-GroupA-25/raw/refs/heads/main/datasets/processed_dataset2_train_data.csv\"\n",
    "# Load the CSV data\n",
    "df = pd.read_csv(csv_url)\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'prompt', 'essay', 'evaluation', 'band', 'cleaned_evaluation','Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar','Overall Band Score', 'word_count', 'sentence_count','avg_sentence_length'\n",
    "df = df[['prompt', 'essay', 'band', 'cleaned_evaluation','Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar','Overall Band Score']]  \n",
    "\n",
    "df.rename(columns={'prompt':'question'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Convert each row to a Document object from the dataframe\n",
    "# if rows > 10 , then break for testing\n",
    "docs = []\n",
    "max_rows = 5000\n",
    "processed_rows = 0\n",
    "for _, row in df.iterrows():\n",
    "    if processed_rows >= max_rows:\n",
    "        break\n",
    "    docs.append(\n",
    "        Document(\n",
    "            page_content=f\"question: {row['question']}\\nessay: {row['essay']}\\nband: {row['band']} \\ncleaned_evaluation: {row['cleaned_evaluation']}\\nTask Achievement: {row['Task Achievement']}\\nCoherence: {row['Coherence']}\\nLexical Resource: {row['Lexical Resource']}\\nGrammar: {row['Grammar']}\\nOverall Band Score: {row['Overall Band Score']}\"\n",
    "        )\n",
    "    )\n",
    "    processed_rows += 1\n",
    "\n",
    "\n",
    "# Initialize text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
    "\n",
    "# Initialize In-Memory Vector Store\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_documents(all_splits)\n",
    "\n",
    "# Load LLM and prompt\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Define State for LLM workflow\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    essay: str\n",
    "    context: List[Document]\n",
    "    graded_response: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieval function\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "# Grading function\n",
    "def grade(state: State):\n",
    "    example_texts = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    user_input = f\"New question: {state['question']}\\nNew Essay: {state['essay']}\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \n",
    "    \"\"\"You are an IELTS examiner. Score the given essay based on the 0-9 IELTS band scale. \n",
    "    The output must be a **valid JSON object** with the following exact keys:\n",
    "    - \"question\" (string): The original essay question.\n",
    "    - \"essay\" (string): The given essay.\n",
    "    - \"overall_score\" (float): A number between 0 and 9.\n",
    "    - \"overall_feedback\" (string): Feedback on overall performance.\n",
    "    - \"task_achievement_score\" (float): A number between 0 and 9.\n",
    "    - \"task_achievement_feedback\" (string): Feedback on task achievement.\n",
    "    - \"coherence_score\" (float): A number between 0 and 9.\n",
    "    - \"coherence_feedback\" (string): Feedback on coherence.\n",
    "    - \"lexical_resource_score\" (float): A number between 0 and 9.\n",
    "    - \"lexical_resource_feedback\" (string): Feedback on lexical resource.\n",
    "    - \"grammar_score\" (float): A number between 0 and 9.\n",
    "    - \"grammar_feedback\" (string): Feedback on grammar.\n",
    "\n",
    "    **Only return a valid JSON object with no extra text, explanations, or formatting.**\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here are some example graded essays:\\n{example_texts}\\n\\nNow, evaluate this new essay:\\n{user_input}\"}\n",
    "    ]\n",
    "    \n",
    "    response = llm.invoke(messages)\n",
    "    return {\"graded_response\": response.content}\n",
    "\n",
    "# Build Graph\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, grade])\n",
    "\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['question', 'essay', 'band', 'cleaned_evaluation', 'Task Achievement',\n",
       "       'Coherence', 'Lexical Resource', 'Grammar', 'Overall Band Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load test data set\n",
    "\n",
    "# Define the GitHub raw CSV URL\n",
    "csv_url_test = \"https://github.com/haydenkerr/INFT3039-Capstone1-GroupA-25/raw/refs/heads/main/datasets/processed_dataset2_test_data.csv\"\n",
    "# Load the CSV data\n",
    "df_test = pd.read_csv(csv_url_test)\n",
    "\n",
    "df_test = df_test[['prompt', 'essay', 'band', 'cleaned_evaluation','Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar','Overall Band Score']]  \n",
    "\n",
    "df_test.rename(columns={'prompt':'question'}, inplace=True)\n",
    "\n",
    "df_test.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Some experts believe that when a country is already rich, any additional increase in economic wealth does not make its citizens any more satisfied. To what extent do you agree or disagree?\n",
      "Essay: Nowadays, most people are more wealthy than in the past, which provide a better quality of lifestyle. However, it is argued that the extra income would not provide extra satisfaction. Personally, I agree with this stance, and the following content will outline the reasons.\n",
      "\n",
      "Firstly, the function of money could lead to happiness. To have enough money, people have no need to have a busy and exhausted lives for earning money, meanwhile, they are also rescued from the financial pressure, such as house rent or bills. As a result, after obtaining enough money for living, people already satisfied, a higher amount is not essensial for their prosperity.\n",
      "\n",
      "In addition, extra income could lead to extra payment. A higher salary means workers should pay more taxes from thier income to the country. For example, some people will buy luxuries when they become wealthy, which need to pay the tax about luxurious products.\n",
      "\n",
      "Furthermore, money does not represent happiness, in contrast, people should learn how to be satisfied from the items they already have. While earning more money, people can have more choices, some of them could be whelmed when they make the decision, nevertheless, more options could also be a problem because people could have more than they need. For instance, accumulated items at home, keep buying luxuries and becomes greedy without satisfy, which will have a negative impact on the family financial and also children's concept of spending money.\n",
      "\n",
      "In conclusion, more income could lead to satisfy of life, however, earning extra money could also have some problems, such as the higher taxes, changes way of spending money could have negative impact on famil\n",
      "Overall Score: 4.5\n",
      "---------\n",
      "---------\n",
      "{\n",
      "    \"coherence_feedback\": \"The essay has a logical structure with a clear introduction, body paragraphs, and conclusion. The use of linking words is generally effective, although some transitions could be smoother. Each paragraph focuses on a specific idea, contributing to the overall coherence of the essay.\",\n",
      "    \"coherence_score\": 6.5,\n",
      "    \"essay\": \"Nowadays, most people are more wealthy than in the past, which provide a better quality of lifestyle. However, it is argued that the extra income would not provide extra satisfaction. Personally, I agree with this stance, and the following content will outline the reasons.\\n\\nFirstly, the function of money could lead to happiness. To have enough money, people have no need to have a busy and exhausted lives for earning money, meanwhile, they are also rescued from the financial pressure, such as house rent or bills. As a result, after obtaining enough money for living, people already satisfied, a higher amount is not essensial for their prosperity.\\n\\nIn addition, extra income could lead to extra payment. A higher salary means workers should pay more taxes from thier income to the country. For example, some people will buy luxuries when they become wealthy, which need to pay the tax about luxurious products.\\n\\nFurthermore, money does not represent happiness, in contrast, people should learn how to be satisfied from the items they already have. While earning more money, people can have more choices, some of them could be whelmed when they make the decision, nevertheless, more options could also be a problem because people could have more than they need. For instance, accumulated items at home, keep buying luxuries and becomes greedy without satisfy, which will have a negative impact on the family financial and also children's concept of spending money.\\n\\nIn conclusion, more income could lead to satisfy of life, however, earning extra money could also have some problems, such as the higher taxes, changes way of spending money could have negative impact on famil\",\n",
      "    \"grammar_feedback\": \"The essay contains a mix of simple and complex sentences. Grammatical errors are present, including errors in article usage, verb tense, and sentence structure (e.g., \\\"people already satisfied\\\"). While these errors do not completely obscure meaning, they do affect the overall clarity and fluency of the writing. Attention to detail in proofreading would improve the grammatical accuracy.\",\n",
      "    \"grammar_score\": 6.0,\n",
      "    \"lexical_resource_feedback\": \"The vocabulary used is adequate for the task, but there is room for improvement in terms of precision and range. Some word choices are slightly inaccurate (e.g., \\\"satisfy of life\\\"). The essay could benefit from the inclusion of more sophisticated vocabulary related to economics and personal satisfaction.\",\n",
      "    \"lexical_resource_score\": 6.0,\n",
      "    \"overall_feedback\": \"The essay addresses the topic and presents a clear position. The arguments are generally relevant but could be developed more fully. The structure is logical, but the conclusion is a bit weak and unfinished. Grammatical errors are present but don't significantly impede understanding. The vocabulary is adequate but could be more precise.\",\n",
      "    \"overall_score\": 6.0,\n",
      "    \"question\": \"Some experts believe that when a country is already rich, any additional increase in economic wealth does not make its citizens any more satisfied. To what extent do you agree or disagree?\",\n",
      "    \"task_achievement_feedback\": \"The essay addresses the prompt and presents a clear stance. The main points are relevant to the topic. However, the examples and explanations could be more developed and directly linked to the central argument. The conclusion is a bit abrupt and could be stronger by summarizing the main points and reiterating the position more clearly.\",\n",
      "    \"task_achievement_score\": 6.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Example test case\n",
    "question_id = 13\n",
    "# word wrap the text output below  \n",
    "pd.set_option('display.max_colwidth',10 )\n",
    "\n",
    "\n",
    "print(\"Question: \"+df_test['question'][question_id])\n",
    "\n",
    "print(\"Essay: \"+df_test['essay'][question_id])\n",
    "print(\"Overall Score: \"+str(df_test[\"Overall Band Score\"][question_id]))\n",
    "\n",
    "new_question = df_test['question'][question_id]\n",
    "new_essay = df_test['essay'][question_id]\n",
    "print(\"---------\")\n",
    " \n",
    "# Run LLM grading\n",
    "result = graph.invoke({\"question\": new_question, \"essay\": new_essay})\n",
    "# print(result)\n",
    "print(\"---------\")\n",
    "json_text = re.search(r\"\\{.*\\}\", result[\"graded_response\"], re.DOTALL)\n",
    "# print(json_text.group())\n",
    "#  clean json_text to change all single quotes to double quotes\n",
    "json_text = json_text.group() #.replace(\"'\", '\"')\n",
    "#  convert string to json\n",
    "\n",
    "\n",
    "if json_text:\n",
    "    single_test_json = json.loads(json_text)\n",
    "else:\n",
    "    single_test_json = json.loads(\"{}\")\n",
    "\n",
    " \n",
    "print(json.dumps(single_test_json, indent=4, sort_keys=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------0\n",
      "---------1\n",
      "---------2\n",
      "---------3\n",
      "---------4\n",
      "---------5\n",
      "---------6\n",
      "---------7\n",
      "---------8\n",
      "---------9\n",
      "---------10\n",
      "---------11\n",
      "---------12\n",
      "---------13\n",
      "---------14\n",
      "---------15\n",
      "---------16\n",
      "---------17\n",
      "---------18\n",
      "---------19\n",
      "---------20\n",
      "---------21\n",
      "---------22\n",
      "---------23\n",
      "---------24\n",
      "---------25\n",
      "---------26\n",
      "---------27\n",
      "---------28\n",
      "---------29\n",
      "---------30\n",
      "---------31\n",
      "---------32\n",
      "---------33\n",
      "---------34\n",
      "---------35\n",
      "---------36\n",
      "---------37\n",
      "---------38\n",
      "---------39\n",
      "---------40\n",
      "---------41\n",
      "---------42\n",
      "---------43\n",
      "---------44\n",
      "---------45\n",
      "---------46\n",
      "---------47\n",
      "---------48\n",
      "---------49\n"
     ]
    }
   ],
   "source": [
    "# for each row in the test data set, run the LLM grading\n",
    "# Run LLM grading for 100 rows\n",
    "rag_results = []\n",
    "processed_rows = 0\n",
    "for _, row in df_test.iterrows():\n",
    "    if processed_rows >= 50:\n",
    "        break\n",
    "    result = graph.invoke({\"question\": row['question'], \"essay\": row['essay']})\n",
    "    # add the results to the rag_results dataframe\n",
    "    # print(\"Question: \"+row['question']+ \"\\n\")\n",
    "    # print(\"Essay: \"+row['essay']+ \"\\n\")\n",
    "    # print(\"Overall Score: \"+str(row[\"Overall Band Score\"])+ \"\\n\")\n",
    "    \n",
    "    print(\"---------\"+str(processed_rows))\n",
    "\n",
    "    json_text = re.search(r\"\\{.*\\}\", result[\"graded_response\"], re.DOTALL)\n",
    "    # print(json_text)\n",
    "    #  clean json_text to change all single quotes to double quotes\n",
    "    json_text = json_text.group() #.replace(\"'\", '\"')\n",
    "    #  convert string to json\n",
    "\n",
    "    if json_text:\n",
    "        result_json = json.loads(json_text)\n",
    "    else:\n",
    "        result_json = json.loads(\"{}\")\n",
    "        \n",
    "   \n",
    " \n",
    "    # print(json.dumps(single_test_json, indent=4, sort_keys=True))\n",
    "    new_row = (row['question'],row['essay'],\n",
    "               float(row[\"Overall Band Score\"]),result_json[\"overall_score\"],\n",
    "               float(row[\"Overall Band Score\"])/float(result_json[\"overall_score\"]),\n",
    "               row[\"cleaned_evaluation\"], result_json[\"overall_feedback\"],\n",
    "               float(row[\"Task Achievement\"]),result_json[\"task_achievement_score\"],result_json[\"task_achievement_feedback\"], \n",
    "               float(row[\"Coherence\"]),result_json[\"coherence_score\"],result_json[\"coherence_feedback\"],\n",
    "               float(row[\"Grammar\"]),result_json[\"grammar_score\"],result_json[\"grammar_feedback\"],\n",
    "               float(row[\"Lexical Resource\"]),result_json[\"lexical_resource_score\"],result_json[\"lexical_resource_feedback\"]\n",
    "               )\n",
    "\n",
    "    rag_results.append(new_row)  \n",
    "    processed_rows += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>essay</th>\n",
       "      <th>Overall Band Score</th>\n",
       "      <th>Predicted Band Score</th>\n",
       "      <th>variation</th>\n",
       "      <th>cleaned_evaluation</th>\n",
       "      <th>Predicted Overall Feedback</th>\n",
       "      <th>Task Achievement</th>\n",
       "      <th>Predicted Task Achievement</th>\n",
       "      <th>Predicted Task Achievement Feedback</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Predicted Coherence</th>\n",
       "      <th>Predicted Coherence Feedback</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Predicted Grammar</th>\n",
       "      <th>Predicted Grammar Feedback</th>\n",
       "      <th>Lexical Resource</th>\n",
       "      <th>Predicted Lexical Resource</th>\n",
       "      <th>Predicted Lexical Resource Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interv...</td>\n",
       "      <td>To agr...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The in...</td>\n",
       "      <td>It is ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The in...</td>\n",
       "      <td>It is ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The in...</td>\n",
       "      <td>The pr...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The re...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The gr...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The in...</td>\n",
       "      <td>In rec...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>The gr...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>The vo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    question      essay  Overall Band Score  Predicted Band Score  variation  \\\n",
       "0  Interv...  To agr...        6.5                 6.5              1.000000   \n",
       "1  The in...  It is ...        8.0                 7.0              1.142857   \n",
       "2  The in...  It is ...        8.5                 6.0              1.416667   \n",
       "3  The in...  The pr...        2.5                 4.0              0.625000   \n",
       "4  The in...  In rec...        4.0                 5.5              0.727273   \n",
       "\n",
       "  cleaned_evaluation Predicted Overall Feedback  Task Achievement  \\\n",
       "0  Task A...          The es...                        6.5          \n",
       "1  Task A...          The es...                        8.5          \n",
       "2  Task A...          The es...                        8.5          \n",
       "3  Task A...          The es...                        3.0          \n",
       "4  Task A...          The es...                        3.5          \n",
       "\n",
       "   Predicted Task Achievement Predicted Task Achievement Feedback  Coherence  \\\n",
       "0        7.0                   The es...                                 7.0   \n",
       "1        7.0                   The es...                                 8.0   \n",
       "2        6.0                   The es...                                 8.0   \n",
       "3        4.0                   The re...                                 2.0   \n",
       "4        6.0                   The es...                                 4.0   \n",
       "\n",
       "   Predicted Coherence Predicted Coherence Feedback  Grammar  \\\n",
       "0        6.5            The es...                        6.5   \n",
       "1        7.0            The es...                        7.0   \n",
       "2        6.5            The es...                        7.0   \n",
       "3        4.5            The es...                        2.0   \n",
       "4        5.5            The es...                        3.5   \n",
       "\n",
       "   Predicted Grammar Predicted Grammar Feedback  Lexical Resource  \\\n",
       "0        6.0          The es...                        6.5          \n",
       "1        7.0          The es...                        7.5          \n",
       "2        6.0          The es...                        7.5          \n",
       "3        4.0          The gr...                        2.5          \n",
       "4        5.5          The gr...                        3.5          \n",
       "\n",
       "   Predicted Lexical Resource Predicted Lexical Resource Feedback  \n",
       "0        6.5                   The es...                           \n",
       "1        7.0                   The es...                           \n",
       "2        6.0                   The es...                           \n",
       "3        4.0                   The vo...                           \n",
       "4        5.5                   The vo...                           "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# convert list of dictionaries to dataframe\n",
    "rag_results = pd.DataFrame(rag_results, columns = ['question','essay','Overall Band Score',\n",
    "                                                   'Predicted Band Score','variation',\n",
    "                                                   'cleaned_evaluation','Predicted Overall Feedback',\n",
    "                                                   'Task Achievement','Predicted Task Achievement','Predicted Task Achievement Feedback',\n",
    "                                                   'Coherence','Predicted Coherence','Predicted Coherence Feedback',\n",
    "                                                   'Grammar','Predicted Grammar','Predicted Grammar Feedback',\n",
    "                                                   'Lexical Resource','Predicted Lexical Resource','Predicted Lexical Resource Feedback'])\n",
    "\n",
    "\n",
    "print(rag_results.shape) #42 rows, 5 columns\n",
    "rag_results.head() # display the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemini_performance_measures\n",
      "mse\n",
      "1.270076863065869\n",
      "rmse\n",
      "1.270076863065869\n",
      "mae\n",
      "1.6130952380952381\n"
     ]
    }
   ],
   "source": [
    "# create measures of accuraacy for coninuous data\n",
    "\n",
    "# Mean Squared Error\n",
    "# Root Mean Squared Error\n",
    "# Mean Absolute Error\n",
    "\n",
    "y_pred = rag_results['Predicted Band Score']\n",
    "y_true = rag_results['Overall Band Score']\n",
    "\n",
    "print(\"gemini_performance_measures\")\n",
    "\n",
    "\n",
    "print(\"mse\")\n",
    "mse = sqrt(mean_squared_error(rag_results['Overall Band Score'], rag_results['Predicted Band Score']))\n",
    "print(mse)\n",
    "\n",
    "print(\"rmse\")\n",
    "rmse = sqrt(mean_squared_error(rag_results['Overall Band Score'], rag_results['Predicted Band Score']))\n",
    "print(rmse)\n",
    "\n",
    "print(\"mae\")\n",
    "mae = mean_squared_error(rag_results['Overall Band Score'], rag_results['Predicted Band Score'])    \n",
    "print(mae)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Overall Feedback Similarity: 0.5559407645463943\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# print(df_test['cleaned_evaluation'][question_id])\n",
    "\n",
    "# get the overall band score feedback between \"Overall Band Score:\" and \"Feedback and Additional Comments:\" from \"cleaned_evaluation\"\n",
    "def get_band_score_feedback(cleaned_evaluation):\n",
    "    start = \"Overall Band Score:\"\n",
    "    end = \"Feedback and Additional Comments:\"\n",
    "    return cleaned_evaluation[cleaned_evaluation.find(start)+len(start):cleaned_evaluation.rfind(end)]\n",
    "\n",
    "def get_task_achievement_feedback(cleaned_evaluation):\n",
    "    start = \"Task Achievement:\"\n",
    "    end = \"Coherence and Cohesion:\"\n",
    "    return cleaned_evaluation[cleaned_evaluation.find(start)+len(start):cleaned_evaluation.rfind(end)]\n",
    "\n",
    "def get_coherence_feedback(cleaned_evaluation):\n",
    "    start = \"Coherence and Cohesion:\"\n",
    "    end = \"Lexical Resource\"\n",
    "    return cleaned_evaluation[cleaned_evaluation.find(start)+len(start):cleaned_evaluation.rfind(end)]\n",
    "\n",
    "def get_lexical_feedback(cleaned_evaluation):\n",
    "    start = \"Lexical Resource\"\n",
    "    end = \"Grammatical Range \"\n",
    "    return cleaned_evaluation[cleaned_evaluation.find(start)+len(start):cleaned_evaluation.rfind(end)]\n",
    "\n",
    "def get_grammar_feedback(cleaned_evaluation):\n",
    "    start = \"Grammatical Range \"\n",
    "    end = \"Overall Band Score:\"\n",
    "    return cleaned_evaluation[cleaned_evaluation.find(start)+len(start):cleaned_evaluation.rfind(end)]\n",
    "\n",
    "rag_results[\"Overall Feedback\"] = rag_results.apply(lambda row: get_band_score_feedback(row[\"cleaned_evaluation\"]), axis=1)\n",
    "rag_results[\"Task Achievement Feedback\"] = rag_results.apply(lambda row: get_task_achievement_feedback(row[\"cleaned_evaluation\"]), axis=1)\n",
    "rag_results[\"Coherence Feedback\"] = rag_results.apply(lambda row: get_coherence_feedback(row[\"cleaned_evaluation\"]), axis=1)\n",
    "rag_results[\"Lexical Feedback\"] = rag_results.apply(lambda row: get_lexical_feedback(row[\"cleaned_evaluation\"]), axis=1)\n",
    "rag_results[\"Grammar Feedback\"] = rag_results.apply(lambda row: get_grammar_feedback(row[\"cleaned_evaluation\"]), axis=1)\n",
    "\n",
    "\n",
    "def compute_similarity(reference, candidate):\n",
    "    ref_embedding = model.encode(reference, convert_to_tensor=True)\n",
    "    cand_embedding = model.encode(candidate, convert_to_tensor=True)\n",
    "    return util.cos_sim(ref_embedding, cand_embedding).item()\n",
    "\n",
    "# Compute similarity for both models\n",
    "rag_results[\"Overall Feedback Similarity\"] = rag_results.apply(lambda row: compute_similarity((row[\"Overall Feedback\"]), row[\"Predicted Overall Feedback\"]), axis=1)\n",
    "rag_results[\"Task Achievement Feedback Similarity\"] = rag_results.apply(lambda row: compute_similarity((row[\"Task Achievement Feedback\"]), row[\"Predicted Task Achievement Feedback\"]), axis=1)\n",
    "rag_results[\"Coherence Feedback Similarity\"] = rag_results.apply(lambda row: compute_similarity((row[\"Coherence Feedback\"]), row[\"Predicted Coherence Feedback\"]), axis=1)\n",
    "rag_results[\"Lexical Feedback Similarity\"] = rag_results.apply(lambda row: compute_similarity((row[\"Lexical Feedback\"]), row[\"Predicted Lexical Resource Feedback\"]), axis=1)\n",
    "rag_results[\"Grammar Feedback Similarity\"] = rag_results.apply(lambda row: compute_similarity((row[\"Grammar Feedback\"]), row[\"Predicted Grammar Feedback\"]), axis=1)\n",
    "\n",
    "# order the dataframe columns to make it easier to read\n",
    "rag_results = rag_results[['question','essay','cleaned_evaluation',\n",
    "                           'Overall Band Score','Predicted Band Score','variation',\n",
    "                           'Overall Feedback','Predicted Overall Feedback','Overall Feedback Similarity',\n",
    "                           'Task Achievement','Predicted Task Achievement','Task Achievement Feedback','Predicted Task Achievement Feedback','Task Achievement Feedback Similarity',\n",
    "                           'Coherence','Predicted Coherence','Coherence Feedback','Predicted Coherence Feedback', 'Coherence Feedback Similarity',\n",
    "                           'Lexical Resource','Predicted Lexical Resource','Lexical Feedback', 'Predicted Lexical Resource Feedback', 'Lexical Feedback Similarity',\n",
    "                           'Grammar','Predicted Grammar','Grammar Feedback','Predicted Grammar Feedback', 'Grammar Feedback Similarity'\n",
    "                           ]]\n",
    "\n",
    "\n",
    "# Print average similarity\n",
    "print(\"Average Overall Feedback Similarity:\", rag_results[\"Overall Feedback Similarity\"].mean())\n",
    "\n",
    "# save to excel file\n",
    "rag_results.to_excel(\"gemini_rag_results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>essay</th>\n",
       "      <th>Overall Band Score</th>\n",
       "      <th>Predicted Band Score</th>\n",
       "      <th>variation</th>\n",
       "      <th>cleaned_evaluation</th>\n",
       "      <th>Overall Feedback</th>\n",
       "      <th>Predicted Overall Feedback</th>\n",
       "      <th>Overall Similarity</th>\n",
       "      <th>Task Achievement</th>\n",
       "      <th>...</th>\n",
       "      <th>Predicted Task Achievement Feedback</th>\n",
       "      <th>Coherence</th>\n",
       "      <th>Predicted Coherence</th>\n",
       "      <th>Predicted Coherence Feedback</th>\n",
       "      <th>Lexical Resource</th>\n",
       "      <th>Predicted Lexical Resource</th>\n",
       "      <th>Predicted Lexical Resource Feedback</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Predicted Grammar</th>\n",
       "      <th>Predicted Grammar Feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interv...</td>\n",
       "      <td>To agr...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>6.5\\n...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>0.739976</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The in...</td>\n",
       "      <td>It is ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>\\n- Co...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>0.440346</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>The es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The in...</td>\n",
       "      <td>It is ...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>\\n\\nCo...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>0.519030</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The es...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>The es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The in...</td>\n",
       "      <td>The pr...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>\\n- Th...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>0.392583</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>The re...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The vo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The in...</td>\n",
       "      <td>In rec...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>Task A...</td>\n",
       "      <td>4\\n- ...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>0.638064</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>The es...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>The es...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>The vo...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>The gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    question      essay  Overall Band Score  Predicted Band Score  variation  \\\n",
       "0  Interv...  To agr...        6.5                 6.5              1.000000   \n",
       "1  The in...  It is ...        8.0                 7.0              1.142857   \n",
       "2  The in...  It is ...        8.5                 6.0              1.416667   \n",
       "3  The in...  The pr...        2.5                 4.0              0.625000   \n",
       "4  The in...  In rec...        4.0                 5.5              0.727273   \n",
       "\n",
       "  cleaned_evaluation Overall Feedback Predicted Overall Feedback  \\\n",
       "0  Task A...           6.5\\n...        The es...                   \n",
       "1  Task A...          \\n- Co...        The es...                   \n",
       "2  Task A...          \\n\\nCo...        The es...                   \n",
       "3  Task A...          \\n- Th...        The es...                   \n",
       "4  Task A...           4\\n- ...        The es...                   \n",
       "\n",
       "   Overall Similarity  Task Achievement  ...  \\\n",
       "0   0.739976                 6.5         ...   \n",
       "1   0.440346                 8.5         ...   \n",
       "2   0.519030                 8.5         ...   \n",
       "3   0.392583                 3.0         ...   \n",
       "4   0.638064                 3.5         ...   \n",
       "\n",
       "   Predicted Task Achievement Feedback Coherence  Predicted Coherence  \\\n",
       "0  The es...                                 7.0        6.5             \n",
       "1  The es...                                 8.0        7.0             \n",
       "2  The es...                                 8.0        6.5             \n",
       "3  The re...                                 2.0        4.5             \n",
       "4  The es...                                 4.0        5.5             \n",
       "\n",
       "   Predicted Coherence Feedback Lexical Resource  Predicted Lexical Resource  \\\n",
       "0  The es...                           6.5              6.5                    \n",
       "1  The es...                           7.5              7.0                    \n",
       "2  The es...                           7.5              6.0                    \n",
       "3  The es...                           2.5              4.0                    \n",
       "4  The es...                           3.5              5.5                    \n",
       "\n",
       "   Predicted Lexical Resource Feedback Grammar  Predicted Grammar  \\\n",
       "0  The es...                               6.5        6.0           \n",
       "1  The es...                               7.0        7.0           \n",
       "2  The es...                               7.0        6.0           \n",
       "3  The vo...                               2.0        4.0           \n",
       "4  The vo...                               3.5        5.5           \n",
       "\n",
       "   Predicted Grammar Feedback  \n",
       "0  The es...                   \n",
       "1  The es...                   \n",
       "2  The es...                   \n",
       "3  The gr...                   \n",
       "4  The gr...                   \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_results.head() # display the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot similarity scores\n",
    "plt.bar([\"RAG\", \"Fine-Tuned GPT\"], [rag_results[\"Overall Similarity\"].mean(), rag_results[\"Fine-Tuned Similarity\"].mean()])\n",
    "plt.ylabel(\"Average Similarity\")\n",
    "plt.title(\"Model Performance Comparison\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0rc3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
